{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11a LSTMs.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMdc6gigLY5anVTUzzfu4g8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/timeSeries/blob/main/11a_LSTMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -l -s https://github.com/cagBRT/timeSeries.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "metadata": {
        "id": "nmW10EmhZ1Ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "def page(num):\n",
        "    return Image(\"LSTM\"+str(num)+ \".png\" , width=640)"
      ],
      "metadata": {
        "id": "S7IqP2QXaD2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Recurrent Neural Networks (RNNs)**"
      ],
      "metadata": {
        "id": "AMnS8WrfaUND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Humans donâ€™t start their thinking from scratch every second. As you read this sentence, you understand each word based on your understanding of previous words. Your thoughts have persistence.<br>\n",
        "So it makes sense that we would have DNNs that have persistence. "
      ],
      "metadata": {
        "id": "c3v8hnAbRLof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use RNNs to connect very recent past information with present information, for example trying to decipher what is happening in a video. <br>"
      ],
      "metadata": {
        "id": "2zFiz88TR054"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "page(1)"
      ],
      "metadata": {
        "id": "wWzK_dZSaI2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we unroll an RNN, we see there are multiple cells for information."
      ],
      "metadata": {
        "id": "Y6i9S-MLaeWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "page(2)"
      ],
      "metadata": {
        "id": "tLuglCbVab2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNNs can learn to predict the very next piece of information, as long as the gap between context and the prediction is small. <br>\n",
        "For example:<br>\n",
        "If we had a sentence, \"The car is on the ????\"<br>\n",
        "It would a fairly straightforward to predict \"road\". The gap between context and prediction is small. "
      ],
      "metadata": {
        "id": "6b9zQfvWa6We"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "page(5)"
      ],
      "metadata": {
        "id": "KkXr0WhVazLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are times when the information we need is not from the very recent past (the previous frame of a video), but from a slightly more distant past. <br>\n",
        "For example:<br><br>\n",
        "I was born in Spain but live in Canada, so I am fluent in English and ????\n",
        "<br><br>\n",
        "As you can see from this example, we need information that is contained at the beginning of the sentence to determine the correct word to finish the sentence. <br><br>"
      ],
      "metadata": {
        "id": "_PyVa_c2SKuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "page(6)"
      ],
      "metadata": {
        "id": "KkIv6Oo6bzMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this kind of task we need Long Short Term Memory Networks"
      ],
      "metadata": {
        "id": "3dXrfLL5TsiK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Long Short-Term Memory Networks (LSTMs)**<br>\n"
      ],
      "metadata": {
        "id": "ZpIgq5c44_JP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference between RNNs and LSTMs is in the architecture of the repeating module.<br>\n",
        "\n",
        "A standard RNN contains a single layer. "
      ],
      "metadata": {
        "id": "Hv4ZjXHscCwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "page(7)"
      ],
      "metadata": {
        "id": "VfD-T84jb4xR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The LSTM contains four interacting layers."
      ],
      "metadata": {
        "id": "0vuXndv-cQTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "page(8)"
      ],
      "metadata": {
        "id": "1pP0_3jXb_fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The architecture of the LSTM means it has the ability to add or remove information. This means the gap between context and prediction can be larger. "
      ],
      "metadata": {
        "id": "WdOSVR_wcZ3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "page(9)"
      ],
      "metadata": {
        "id": "4vOS2fYxcWtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTMs are a special class of Recurrent Neural Networks (RNNs).<br>\n",
        "They can learn long term dependencies."
      ],
      "metadata": {
        "id": "XPAhef80Q_lp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Univariate LSTM Models**"
      ],
      "metadata": {
        "id": "Sp1eNTiL5dST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preparation**<br>\n",
        "[10, 20, 30, 40, 50, 60, 70, 80, 90]<br>\n",
        "\n",
        "The above sequence can be changed for the model\n",
        "\n",
        "X__________y <br>\n",
        "10, 20, 30  40<br>\n",
        "20, 30, 40  50<br>\n",
        "30, 40, 50  60"
      ],
      "metadata": {
        "id": "A1zwvU4t5s83"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UwEu1Im4dlV"
      },
      "outputs": [],
      "source": [
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "  X, y = list(), list()\n",
        "  for i in range(len(sequence)):\n",
        "    # find the end of this pattern\n",
        "    end_ix = i + n_steps\n",
        "    # check if we are beyond the sequence\n",
        "    if end_ix > len(sequence)-1:\n",
        "     break\n",
        "    # gather input and output parts of the pattern\n",
        "    seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "    X.append(seq_x)\n",
        "    y.append(seq_y)\n",
        "  return array(X), array(y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "metadata": {
        "id": "Mq0DVeZv7FLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare the data**"
      ],
      "metadata": {
        "id": "0jX97sQy8z5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]"
      ],
      "metadata": {
        "id": "YEw5N4Kj7OWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_steps = 3\n",
        "n_features = 1\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "# summarize the data\n",
        "for i in range(len(X)):\n",
        "  print(X[i], y[i])"
      ],
      "metadata": {
        "id": "M6ObpfBg7UxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using an off-the-shelf LSTM model** "
      ],
      "metadata": {
        "id": "1U2ZnXDv7ZME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features))) \n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "NiETxIby7wci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=200, verbose=0)"
      ],
      "metadata": {
        "id": "ce6dw-dM8Ex0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model, show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "5oJwllzT8RHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make a Prediction**<br>\n",
        "We are expecting:<br>\n",
        "100"
      ],
      "metadata": {
        "id": "oYFffDsG8hl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps, n_features))"
      ],
      "metadata": {
        "id": "iu2xnUwO8Tcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "id": "WZ-eWnfh8ev9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}