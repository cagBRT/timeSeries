{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10c MultiHeaded CNN Models.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO/BEkWn2UWd4grB+fTKmox",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/timeSeries/blob/main/10c_MultiHeaded_CNN_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MultiHeaded CNN Models**"
      ],
      "metadata": {
        "id": "WZN57B5X-yje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just as we did with the multiHeaded MLPs, we can create multiheaded CNNs"
      ],
      "metadata": {
        "id": "_QdV2TTh-8hc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiheaded models can often be more flexible and/or more accurate than a single headed model."
      ],
      "metadata": {
        "id": "UtndB-mO_HZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The split_Sequences function**"
      ],
      "metadata": {
        "id": "Ib53pV2LBr8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_sequences(sequences, n_steps): \n",
        "  X, y = list(), list()\n",
        "  for i in range(len(sequences)):\n",
        "    # find the end of this pattern\n",
        "    end_ix = i + n_steps\n",
        "    # check if we are beyond the dataset\n",
        "    if end_ix > len(sequences): \n",
        "      break\n",
        "    # gather input and output parts of the pattern\n",
        "    seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1] \n",
        "    X.append(seq_x)\n",
        "    y.append(seq_y)\n",
        "  return array(X), array(y)"
      ],
      "metadata": {
        "id": "7FT6cO32_u16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The libraries**"
      ],
      "metadata": {
        "id": "vtXFCLCGBwy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D \n",
        "from keras.layers.merge import concatenate\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "metadata": {
        "id": "fYAmQTyk_job"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating a time series**"
      ],
      "metadata": {
        "id": "I62be4OIBzZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+(2*in_seq2[i]) for i in range(len(in_seq1))])\n",
        "# convert to [rows, columns] structure \n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1)) \n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1)) \n",
        "out_seq = out_seq.reshape((len(out_seq), 1)) \n",
        "# horizontally stack columns\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))"
      ],
      "metadata": {
        "id": "6KtacqENB9Nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "sPnm0M0sB-dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps)\n",
        "# one time series per head\n",
        "n_features = 1\n",
        "X1 = X[:, :, 0].reshape(X.shape[0], X.shape[1], n_features) \n",
        "X2 = X[:, :, 1].reshape(X.shape[0], X.shape[1], n_features) "
      ],
      "metadata": {
        "id": "3PBSsh3QCDOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First head**"
      ],
      "metadata": {
        "id": "lmWXtEavCFmU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LrXhtID9wva"
      },
      "outputs": [],
      "source": [
        "head1 = Input(shape=(n_steps, n_features)) \n",
        "cnn1 = Conv1D(20, 2, activation='relu')(head1) \n",
        "cnn1 = MaxPooling1D()(cnn1)\n",
        "cnn1 = Flatten()(cnn1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Second head**"
      ],
      "metadata": {
        "id": "VKS1eWPJCINW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "head2 = Input(shape=(n_steps, n_features)) \n",
        "cnn2 = Conv1D(20, 2, activation='relu')(head2) \n",
        "cnn2 = MaxPooling1D()(cnn2)\n",
        "cnn2 = Flatten()(cnn2)"
      ],
      "metadata": {
        "id": "etP_hOpm_X7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Merge the two heads into one model**"
      ],
      "metadata": {
        "id": "B9_T5dI0COXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merge = concatenate([cnn1, cnn2])\n",
        "dense = Dense(20, activation='relu')(merge)\n",
        "output = Dense(1)(dense)\n",
        "model = Model(inputs=[head1, head2], outputs=output) "
      ],
      "metadata": {
        "id": "7EFPSjx1Ak7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "sAeuIDZCCUCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot the model architecture**"
      ],
      "metadata": {
        "id": "KIAcE3AkCWZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model, show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "26dwzgdEBODF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model**"
      ],
      "metadata": {
        "id": "31QMIJqXCagS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([X1, X2], y, epochs=100, verbose=0)"
      ],
      "metadata": {
        "id": "LMKen4zyBdbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make a prediction**"
      ],
      "metadata": {
        "id": "MWejn_5ZCdB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_input = array([[80, 85], [90, 95], [100, 105]])\n",
        "x1 = x_input[:, 0].reshape((1, n_steps, n_features))\n",
        "x2 = x_input[:, 1].reshape((1, n_steps, n_features))\n",
        "yhat = model.predict([x1, x2], verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "id": "oVivTvxdBad2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment:**<br>\n",
        "Change the number of epochs and neurons in the model to improve the prediction. <br>\n",
        "The number of neurons in the two input models should be the same"
      ],
      "metadata": {
        "id": "syW28auuCwzh"
      }
    }
  ]
}