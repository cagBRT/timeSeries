{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6 TimeSeriesForecasting",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNx8wmzVVJ5F9SB5j+2VCIn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/timeSeries/blob/main/6_TimeSeriesForecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6yny9P_HJ0S"
      },
      "source": [
        "Prerequisite for this notebook is:\n",
        ">[5: TimeSeriesForecasting.ipynb](https://colab.research.google.com/drive/11B5w7z3oGqgeDi_6mGe8aKTKcuO6P4x3#scrollTo=eiZsm3AuTNwx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq9XmLDs2688"
      },
      "source": [
        "In this notebook you look at furniture and office supply sales over a four year period. Then you create models to forecast future sales.<br>\n",
        "\n",
        "https://algorithmia.com/blog/an-introduction-to-time-series-forecasting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPDTx8q0tR4b"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/cagBRT/timeSeries.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx2aGtTz3NNP"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "517XXH7TnCpS"
      },
      "source": [
        "import warnings\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.style.use('fivethirtyeight')\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHtlM9NYjUTV"
      },
      "source": [
        "matplotlib.rcParams['axes.labelsize'] = 14\n",
        "matplotlib.rcParams['xtick.labelsize'] = 12\n",
        "matplotlib.rcParams['ytick.labelsize'] = 12\n",
        "matplotlib.rcParams['text.color'] = 'k'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28W-DbaO3Ros"
      },
      "source": [
        "# **Get and prepare the data**<br>\n",
        "It is in the form of an Excel spreadsheet, use Pandas to read in the data. <br>\n",
        "The data is from a Superstore that sells furniture and office supplies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFbMSAw1sAJ0"
      },
      "source": [
        "df = pd.read_excel(\"Sample - Superstore.xls\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdzTIRsw6RDe"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVQB6b9S6mZr"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "644eUwQ0jyXr"
      },
      "source": [
        "Save the rows on furniture sales in a variable called furniture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_VEoVNp6jyt"
      },
      "source": [
        "furniture = df.loc[df['Category'] == 'Furniture']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsgrGxUA3bXg"
      },
      "source": [
        "The data spans the time Jan.,2014 to Dec.,2017"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHTUaY0_vZGv"
      },
      "source": [
        "furniture['Order Date'].min(), furniture['Order Date'].max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HitLgD73mXE"
      },
      "source": [
        "Check for missing data and only keep the Order Date and Sales columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoONUx6ZvfB2"
      },
      "source": [
        "cols = ['Row ID', 'Order ID', 'Ship Date', 'Ship Mode', 'Customer ID', \n",
        "        'Customer Name', 'Segment', 'Country', 'City', 'State', 'Postal Code',\n",
        "        'Region', 'Product ID', 'Category', 'Sub-Category', 'Product Name', \n",
        "        'Quantity', 'Discount', 'Profit']\n",
        "furniture.drop(cols, axis=1, inplace=True)\n",
        "furniture = furniture.sort_values('Order Date')\n",
        "print(\"Null sums: \",furniture.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP7X6BJE5BMM"
      },
      "source": [
        "furniture"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruvj_GBm4zMb"
      },
      "source": [
        "Put the data into order of earliest date to latest date. <br>\n",
        "Reset the index so the earliest date is index 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz4KZgbSvj5s"
      },
      "source": [
        "furniture = furniture.groupby('Order Date')['Sales'].sum().reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m4ozsXwvlvU"
      },
      "source": [
        "furniture"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwImE2Kh5p10"
      },
      "source": [
        "Change the index from row number to the date. <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLjAReDXvpNB"
      },
      "source": [
        "furniture = furniture.set_index('Order Date')\n",
        "furniture.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0F8XrZ_lRNM"
      },
      "source": [
        "The data is now two columns, order data and Sales<br>\n",
        "It is ordered from the earliest date to the latest date.<br>\n",
        "Sales for every day are recorded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGKHDoz-vtgx"
      },
      "source": [
        "furniture"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXhowCiX7OVD"
      },
      "source": [
        "Group the sales into months by adding all the sales for each month together. The date for the month will be the first day of the month"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCwiO8Y4vv4z"
      },
      "source": [
        "#y = furniture['Sales'].resample('MS').mean()\n",
        "monthlySales = furniture['Sales'].resample('MS').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jddnxND9v0pj"
      },
      "source": [
        "print(monthlySales['2016'])\n",
        "print(\"-------End 2016--------------\")\n",
        "print(monthlySales['2017'])\n",
        "print(\"----------End 2017-----------\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iTCrEjD_kC5"
      },
      "source": [
        "Plot the monthly sales for furniture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDf67Nr0wKyp"
      },
      "source": [
        "monthlySales.plot(figsize=(15, 6))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEIQ6B0_Unw6"
      },
      "source": [
        "# **Decompose the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhJgpENYAo0V"
      },
      "source": [
        "Using time series decomposition, we can decompose the time series into three components: <br>\n",
        "- trend<br>\n",
        "- seasonality<br>\n",
        "- noise (residual)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGZRQ1xHwm1M"
      },
      "source": [
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 15, 8\n",
        "decomposition = sm.tsa.seasonal_decompose(monthlySales, model='additive')\n",
        "fig = decomposition.plot()\n",
        "fig.suptitle(\"Montly Sales Decomposed\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIoVvZ7mwy8u"
      },
      "source": [
        "# **ARIMA (Autoregressive Integrated Moving Average)**<br>\n",
        "ARIMA models are denoted with the notation ARIMA(p, d, q). These three parameters account for seasonality, trend, and noise in data. <br><br>\n",
        "p,d,q are given a range of values 0,1,2. <br>\n",
        "These ranges are used to do a grid search to find the optimal pdq parameters for the model and data. <br>\n",
        "The model is run with each combination of pdq.<br>\n",
        "The best performing combination (the one with the lowest AIC) is kept. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_o59AAoi_4e"
      },
      "source": [
        "ARIMA is actually a class of models that ‘explains’ a given time series based on its own past values, that is, its own lags and the lagged forecast errors, so that equation can be used to forecast future values.\n",
        "\n",
        "Any ‘non-seasonal’ time series that exhibits patterns and is not a random white noise can be modeled with ARIMA models.\n",
        "\n",
        "An ARIMA model is characterized by 3 terms: p, d, q\n",
        "\n",
        "where,\n",
        "\n",
        "p is the order of the AR term\n",
        "\n",
        "q is the order of the MA term\n",
        "\n",
        "d is the number of differencing required to make the time series stationary\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtODTTXPkZHO"
      },
      "source": [
        "If a time series, has seasonal patterns, then you need to add seasonal terms and it becomes SARIMA, short for ‘Seasonal ARIMA’. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWKP1ydiWphu"
      },
      "source": [
        "# **Seasonal-ARIMA (SARIMA)**<br>\n",
        "[SARIMA](https://www.statsmodels.org/stable/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html)<br>\n",
        "<br>\n",
        "SARIMAX is much like ARIMA, but a little more complicated. Not only do you have to use a loop and grid search for the optimal values of p, d, and q, but you have to also use a nested loop and grid search for the seasonal values for p, d, and q.\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZaGiZI_eiQr"
      },
      "source": [
        "The (P,D,Q,s) order of the seasonal component of the model for the AR parameters, differences, MA parameters, and periodicity.<br>\n",
        "\n",
        "s is an integer giving the periodicity (number of periods in season), often it is 4 for quarterly data or 12 for monthly data. Default is no seasonal effect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlvCJNtjwz7n"
      },
      "source": [
        "p = d = q = range(0, 2)\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "#12 is for monthly data\n",
        "seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
        "print('Examples of parameter combinations for Seasonal ARIMA...')\n",
        "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))\n",
        "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))\n",
        "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))\n",
        "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[4]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kLscguWXj8S"
      },
      "source": [
        "**Find the best p,d,q combination**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kTVcQX1w6eo"
      },
      "source": [
        "for param in pdq:\n",
        "    for param_seasonal in seasonal_pdq:\n",
        "        try:\n",
        "            model = sm.tsa.statespace.SARIMAX(monthlySales,\n",
        "                                            order=param,\n",
        "                                            seasonal_order=param_seasonal,\n",
        "                                            enforce_stationarity=False,\n",
        "                                            enforce_invertibility=False)\n",
        "            results = model.fit()\n",
        "            print('ARIMA{}x{}12 - AIC:{}'.format(param, param_seasonal, results.aic))\n",
        "        except:\n",
        "            continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJG-Tg2SagRC"
      },
      "source": [
        "**The Akaike Information Critera (AIC)** is a widely used measure of a statistical model. <br>\n",
        "It basically quantifies<br>\n",
        "1) the goodness of fit<br>\n",
        "2) the simplicity/parsimony, of the model into a single statistic.\n",
        "\n",
        "**When comparing two models, the one with the lower AIC is generally “better”**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wkGWkDMxREE"
      },
      "source": [
        "The above output suggests that SARIMAX(1, 1, 1)x(1, 1, 0, 12) yields the lowest AIC value of 297.78. Therefore we should consider this to be optimal option.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zQzdkmiYczO"
      },
      "source": [
        "# **Train the Model**<br>\n",
        "The choosen model is trained on the data<br>\n",
        "- order: (p,d,q) order of the model for the number of AR parameters, differences, and MA parameters\n",
        "- seasonal_order: (P,D,Q,s) order of the seasonal component of the model for the AR parameters, differences, MA parameters, and periodicity\n",
        "- enforce_stationarity: Whether or not to transform the AR parameters to enforce stationarity in the autoregressive component of the model\n",
        "- [enforce_invertibility](https://medium.com/@kfoofw/arma-causality-and-invertibility-of-stationary-time-series-971b7d87b79c): Whether or not to transform the MA parameters to enforce invertibility in the moving average component of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsEG-10hxR6Q"
      },
      "source": [
        "modelTrained = sm.tsa.statespace.SARIMAX(monthlySales,\n",
        "                                order=(1, 1, 1),\n",
        "                                seasonal_order=(1, 1, 0, 12),\n",
        "                                enforce_stationarity=False,\n",
        "                                enforce_invertibility=False)\n",
        "results = modelTrained.fit()\n",
        "print(results.summary().tables[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp9fwrSnf9qc"
      },
      "source": [
        "**The model summary above** contains the ‘Covariance Type’ graph, which depicts each of the variables’ impact on the forecast. \n",
        "\n",
        "We have three main lagged AR and MA variables. \n",
        "\n",
        "- The first set of AR and MA variables is lagged by 1 time step (ar.L1 and ma.L1, respectively), \n",
        "\n",
        "- The second ar is lagged by 12 time steps (ar.S.L12).\n",
        "<br>\n",
        "Looking at the ‘P>abs(z)’ term in the graph we want our P values to be as close to 0 as possible.<br> Using a cutoff of <0.05 for statistical significance, our MA term significantly impacts model forecast."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DunFu3ZvxgC6"
      },
      "source": [
        "Now, run the model diagnostics. It will hopefully show any unusal behavior. <br>\n",
        "In this case, our model diagnostics suggests that the model residuals are near normally distributed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcD2HxjDhRMp"
      },
      "source": [
        "**Residuals**<br>\n",
        "**Residual is the difference between true and predicted value**. <br>\n",
        "If there are correlations between residuals - there is information left in the residuals which should be used in computing forecasts. If the residuals have a mean other than zero, then the forecasts are biased. For instance if we have a constantly growing residual like (... -0.3, -0.2, 0.1, 0, 0.1, 0.2, 0.3, ... and so on, the mean will be 0) it means that our model does not fully depict the process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31tVnB5UiGGE"
      },
      "source": [
        "**Histogram** plus estimated density:  of standardized residuals, along with a Normal(0,1) density plotted for reference. <br><br>\n",
        "[Kernel density estimation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.plot.kde.html) (KDE) is a non-parametric way to estimate the probability density function (PDF) of a random variable. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2n89y9FjTXV"
      },
      "source": [
        "**Normal Q-Q plot, with Normal reference line**<br><br>\n",
        "**Normal Q–Q (quantile-quantile) plot** is a probability plot, which is a graphical method for comparing two probability distributions by plotting their quantiles against each other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me567TVNk8Ti"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(\"normalQQPlot.png\" , width=640)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N5rVmLUjAuq"
      },
      "source": [
        "**Correlogram**: correlogram is a commonly used tool for checking randomness in a data set. <br>\n",
        "**If random, autocorrelations should be near zero** for any and all time-lag separations. <br><br>\n",
        "If non-random, then one or more of the autocorrelations will be significantly non-zero.<br>\n",
        "\n",
        "In addition, correlograms are used in the model identification stage for Box–Jenkins autoregressive moving average time series models. **Autocorrelations should be near-zero for randomness**; *if the analyst does not check for randomness, then the validity of many of the statistical conclusions becomes suspect*. The correlogram is an excellent way of checking for such randomness."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UhqfsywxXiH"
      },
      "source": [
        "results.plot_diagnostics(figsize=(16, 8))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szl-agE4nl6o"
      },
      "source": [
        "**Making predictions with the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bauY5Cd2nv0v"
      },
      "source": [
        "To understand the accuracy of our forecasts, we compare predicted sales to real sales of the time series, and we set forecasts to start at 2017–01–01 to the end of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq9iUpaan5i7"
      },
      "source": [
        "The line plot is showing the observed values compared to the rolling forecast predictions. <br><br>\n",
        "Overall, our forecasts align with the true values very well, showing an upward trend starts from the beginning of the year and captured the seasonality toward the end of the year."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY6JShUsxhmB"
      },
      "source": [
        "#Assignment 1 - change the date here\n",
        "pred = results.get_prediction(start=pd.to_datetime('2017-01-01'), dynamic=False)\n",
        "pred_ci = pred.conf_int()\n",
        "ax = monthlySales['2014':].plot(label='observed')\n",
        "pred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=.7, figsize=(14, 7))\n",
        "ax.fill_between(pred_ci.index,\n",
        "                pred_ci.iloc[:, 0],\n",
        "                pred_ci.iloc[:, 1], color='k', alpha=.2)\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Furniture Sales')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dVli4ZroGE5"
      },
      "source": [
        "The MSE is a measure of the quality of an estimator — it is always non-negative, and the smaller the MSE, the closer we are to finding the line of best fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaFwTQwZxrb1"
      },
      "source": [
        "monthlySales_forecasted = pred.predicted_mean\n",
        "monthlySales_truth = monthlySales['2017-01-01':]\n",
        "mse = ((monthlySales_forecasted - monthlySales_truth) ** 2).mean()\n",
        "print('The Mean Squared Error of our forecasts is {}'.format(round(mse, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "079niFIboNRp"
      },
      "source": [
        "Root Mean Square Error (RMSE) tells us that our model was able to forecast the average daily furniture sales in the test set within 151.64 of the real sales. <br><br>\n",
        "Our furniture daily sales range from around 400 to over 1200. This is a pretty good model so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od4a05G0xvDh"
      },
      "source": [
        "print('The Root Mean Squared Error of our forecasts is {}'.format(round(np.sqrt(mse), 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-kh6f4QoXWf"
      },
      "source": [
        "**Producing and visualizing forecasts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WTd4M4cohDu"
      },
      "source": [
        "The model clearly captures furniture sales seasonality. <br><br>\n",
        "As we forecast further out into the future, it is natural for us to become less confident in our values. This is reflected by the confidence intervals generated by our model, which grow larger as we move further out into the future."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eue_Ub7x30w"
      },
      "source": [
        "pred_uc = results.get_forecast(steps=100)\n",
        "pred_ci = pred_uc.conf_int()\n",
        "ax = monthlySales.plot(label='observed', figsize=(14, 7))\n",
        "pred_uc.predicted_mean.plot(ax=ax, label='Forecast')\n",
        "ax.fill_between(pred_ci.index,\n",
        "                pred_ci.iloc[:, 0],\n",
        "                pred_ci.iloc[:, 1], color='k', alpha=.25)\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Furniture Sales')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbVvFK0I_bE5"
      },
      "source": [
        "# **Assignment 1**<br>\n",
        "Change the date in the predictions code. <br>\n",
        "Chage the date from 2017-01-01 to 2016-01-01\n",
        "\n",
        "What happens to the prediction? \n",
        "Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWsacsDb_wrr"
      },
      "source": [
        "# **Assignment 2**<br>\n",
        "We used the grid search method to find the best combinatiomn of p,d,q<br>\n",
        "Now go back and pick a different combination of p,d,q. It can be the second best, the worst, or some combination in between. <br>\n",
        "Compare the changes in the prediction between the runs. Try several combinations. "
      ]
    }
  ]
}