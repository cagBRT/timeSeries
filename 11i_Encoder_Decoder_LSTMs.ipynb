{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11i Encoder-Decoder LSTMs.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNZmqDPJL/IWL59f1nhEESi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/timeSeries/blob/main/11i_Encoder_Decoder_LSTMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Encoder-Decoder LSTMs**"
      ],
      "metadata": {
        "id": "9bG_DUtXEXEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A model specifically developed for forecasting variable length output sequences is called the Encoder-Decoder LSTM. <br>\n",
        "The model was designed for prediction problems where there are both input and output sequences, so-called sequence-to-sequence, or seq2seq problems, such as translating text from one language to another. <br>\n",
        "This model can be used for multi-step time series forecasting. As its name suggests, the model is comprised of two sub-models: the encoder and the decoder.<br><br>\n",
        "*Jason Bownlee, Machine Learning Mastery*"
      ],
      "metadata": {
        "id": "BTJX8LhbEgYG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIHuCJTOELUN"
      },
      "outputs": [],
      "source": [
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.layers import LeakyReLU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
        "  X, y = list(), list()\n",
        "  for i in range(len(sequence)):\n",
        "    # find the end of this pattern\n",
        "    end_ix = i + n_steps_in\n",
        "    out_end_ix = end_ix + n_steps_out\n",
        "    # check if we are beyond the sequence\n",
        "    if out_end_ix > len(sequence):\n",
        "      break\n",
        "    # gather input and output parts of the pattern\n",
        "    seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
        "    X.append(seq_x)\n",
        "    y.append(seq_y)\n",
        "  return array(X), array(y)"
      ],
      "metadata": {
        "id": "QaOwkY71FTD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_seq = [10, 22, 35, 43, 55, 64, 75, 85, 95]"
      ],
      "metadata": {
        "id": "qBvqdY2BGaS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# choose a number of time steps\n",
        "n_steps_in, n_steps_out = 3, 2\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "y = y.reshape((y.shape[0], y.shape[1], n_features))"
      ],
      "metadata": {
        "id": "QaCnDfjOGHdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create the model**"
      ],
      "metadata": {
        "id": "wqN0Uc1MGsME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The encoder:**<br>\n",
        "reads and interperts the input sequence"
      ],
      "metadata": {
        "id": "-Yr3G0A6GzvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(100, activation='relu', input_shape=(n_steps_in, n_features))) "
      ],
      "metadata": {
        "id": "epVg_FMaGn2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The decoder:**<br>\n",
        "The output of the encoder is repeated, once for each time step"
      ],
      "metadata": {
        "id": "YVLyMZGNIhzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(RepeatVector(n_steps_out))"
      ],
      "metadata": {
        "id": "J2lt5IzpIwMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the decoder**"
      ],
      "metadata": {
        "id": "yOziALLOI_cB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(LSTM(100, activation='relu', return_sequences=True)) "
      ],
      "metadata": {
        "id": "T0TAxEqhI5T-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the same output layers tomake each one-step prediction in the output sequence"
      ],
      "metadata": {
        "id": "oENvhMplJEa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(TimeDistributed(Dense(1)))"
      ],
      "metadata": {
        "id": "bdD6s_OiGRL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compile and train the model**"
      ],
      "metadata": {
        "id": "GCr0tTqxJUeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=50, verbose=0)"
      ],
      "metadata": {
        "id": "f_WhFvzvJUrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model, show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "SOmkezuiKuuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make a prediction**:<br>\n",
        "Expect:\n",
        "106, 120"
      ],
      "metadata": {
        "id": "p6lMmXbBJw8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_input = array([75, 85, 95])\n",
        "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "id": "6ym0gkzsGHfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment**: \n",
        "1. Try different activation functions.(LeakyReLU) Does it change the prediction accuracy?\n",
        "2. Change the number of epochs, and the input sequence, what is the change in the accuracy?"
      ],
      "metadata": {
        "id": "tCtQUBpnKLkc"
      }
    }
  ]
}